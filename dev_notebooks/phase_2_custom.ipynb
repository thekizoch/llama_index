{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for local docker instance, using windows on anaconda prompt, run below\n",
    "\n",
    " ```\n",
    " docker run ^\n",
    "    -p 7474:7474 -p 7687:7687 ^\n",
    "    -v \"%CD%/data:/data\" -v \"%CD%/plugins:/plugins\" ^\n",
    "    --name neo4j-apoc ^\n",
    "    -e NEO4J_apoc_export_file_enabled=true ^\n",
    "    -e NEO4J_apoc_import_file_enabled=true ^\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true ^\n",
    "    -e NEO4JLABS_PLUGINS=\"[\\\"apoc\\\"]\" ^\n",
    "    neo4j:latest\n",
    "```\n",
    "\n",
    "for mac or linux, use below\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
    "\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "url = \"bolt://localhost:7687\"\n",
    "\n",
    "graph_store = Neo4jPGStore(username=username, password=password, url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_env\n",
    "\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_abstracts = [\n",
    "    \"\"\"Aneuploidy, a deviation in chromosome numbers from the normal diploid set, is now\n",
    "recognized as a fundamental characteristic of all cancer types and is found in 70–90% of all solid tu-\n",
    "mors. The majority of aneuploidies are generated by chromosomal instability (CIN). CIN/aneuploidy\n",
    "is an independent prognostic marker of cancer survival and is a cause of drug resistance. Hence,\n",
    "ongoing research has been directed towards the development of therapeutics aimed at targeting\n",
    "CIN/aneuploidy. However, there are relatively limited reports on the evolution of CIN/aneuploidies\n",
    "within or across metastatic lesions. In this work, we built on our previous studies using a human\n",
    "xenograft model system of metastatic disease in mice that is based on isogenic cell lines derived\n",
    "from the primary tumor and specific metastatic organs (brain, liver, lung, and spine). As such, these\n",
    "studies were aimed at exploring distinctions and commonalities between the karyotypes; biologi-\n",
    "cal processes that have been implicated in CIN; single-nucleotide polymorphisms (SNPs); losses,\n",
    "gains, and amplifications of chromosomal regions; and gene mutation variants across these cell lines.\n",
    "Substantial amounts of inter- and intra-heterogeneity were found across karyotypes, along with\n",
    "distinctions between SNP frequencies across each chromosome of each metastatic cell line relative\n",
    "the primary tumor cell line. There were disconnects between chromosomal gains or amplifications\n",
    "and protein levels of the genes in those regions. However, commonalities across all cell lines provide\n",
    "opportunities to select biological processes as druggable targets that could have efficacy against the\n",
    "primary tumor, as well as metastases.\n",
    "Cancers 2023, 15, 1420. https://doi.org/10.3390/cancers15051420 https://www.mdpi.com/journal/cancers\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "Colon cancer is a common malignancy and a major contributor to human morbidity and\n",
    "mortality. In this study, we explore the expression and prognostic impact of IRS-1, IRS-2, RUNx3,\n",
    "and SMAD4 in colon cancer. Furthermore, we elucidate their correlations with miRs 126, 17-5p,\n",
    "and 20a-5p, which are identified as potential regulators of these proteins. Tumor tissue from 452\n",
    "patients operated for stage I–III colon cancer was retrospectively collected and assembled into tissue\n",
    "microarrays. Biomarkers’ expressions were examined by immunohistochemistry and analyzed\n",
    "using digital pathology. In univariate analyses, high expression levels of IRS1 in stromal cytoplasm,\n",
    "RUNX3 in tumor (nucleus and cytoplasm) and stroma (nucleus and cytoplasm), and SMAD4 in\n",
    "tumor (nucleus and cytoplasm) and stromal cytoplasm were related to increased disease-specific\n",
    "survival (DSS). In multivariate analyses, high expression of IRS1 in stromal cytoplasm, RUNX3\n",
    "in tumor nucleus and stromal cytoplasm, and high expression of SMAD4 in tumor and stromal\n",
    "cytoplasm remained independent predictors of improved DSS. Surprisingly, with the exception of\n",
    "weak correlations (0.2 < r < 0.25) between miR-126 and SMAD4, the investigated markers were mostly\n",
    "uncorrelated with the miRs. However, weak to moderate/strong correlations (0.3 < r < 0.6) were\n",
    "observed between CD3 and CD8 positive lymphocyte density and stromal RUNX3 expression. High\n",
    "expression levels of IRS1, RUNX3, and SMAD4 are positive prognostic factors in stage I–III colon\n",
    "cancer. Furthermore, stromal expression of RUNX3 is associated with increased lymphocyte density,\n",
    "suggesting that RUNX3 is an important mediator during recruitment and activation of immune cells\n",
    "in colon cancer.\"\"\",\n",
    "]\n",
    "# \"\"\"B cells have recently become a focus in breast cancer pathology due to their influence\n",
    "# on tumour regression, prognosis, and response to treatment, besides their contribution to antigen\n",
    "# presentation, immunoglobulin production, and regulation of adaptive responses. As our under-\n",
    "# standing of diverse B cell subsets in eliciting both pro- and anti-inflammatory responses in breast\n",
    "# cancer patients increases, it has become pertinent to address the molecular and clinical relevance\n",
    "# of these immune cell populations within the tumour microenvironment (TME). At the primary\n",
    "# tumour site, B cells are either found spatially dispersed or aggregated in so-called tertiary lymphoid\n",
    "# structures (TLS). In axillary lymph nodes (LNs), B cell populations, amongst a plethora of activities,\n",
    "# undergo germinal centre reactions to ensure humoral immunity. With the recent approval for the\n",
    "# addition of immunotherapeutic drugs as a treatment option in the early and metastatic settings\n",
    "# for triple-negative breast cancer (TNBC) patients, B cell populations or TLS may resemble valuable\n",
    "# biomarkers for immunotherapy responses in certain breast cancer subgroups. New technologies\n",
    "# such as spatially defined sequencing techniques, multiplex imaging, and digital technologies have\n",
    "# further deciphered the diversity of B cells and the morphological structures in which they appear in\n",
    "# the tumour and LNs. Thus, in this review, we comprehensively summarise the current knowledge of\n",
    "# B cells in breast cancer. In addition, we provide a user-friendly single-cell RNA-sequencing platform,\n",
    "# called “B singLe cEll rna-Seq browSer” (BLESS) platform, with a focus on the B cells in breast cancer\n",
    "# patients to interrogate the latest publicly available single-cell RNA-sequencing data collected from\n",
    "# diverse breast cancer studies. Finally, we explore their clinical relevance as biomarkers or molecular\n",
    "# targets for future interventions.\"\"\",\n",
    "# \"\"\"Background: The 21-gene Oncotype DX Breast Recurrence Score® assay is prognostic and\n",
    "# predictive of chemotherapy benefit for patients with estrogen receptor-positive, HER2−early breast\n",
    "# cancer (EBC). The KARMA Dx study evaluated the impact of the Recurrence Score® results (RS) on\n",
    "# the treatment decision for patients with EBC and high-risk clinicopathological characteristics for\n",
    "# whom chemotherapy (CT) was considered. Methods: Eligible patients with EBC were candidates\n",
    "# for the study if CT was considered standard recommendation by local guidelines. Three high-risk\n",
    "# EBC cohorts were predefined: (A) pT1-2, pN0/N1mi, and grade 3; (B) pT1-2, pN1, and grades 1–2;\n",
    "# and (C) neoadjuvant cT2-3, cN0, and Ki67 ≤ 30%. Treatment recommendations before and after\n",
    "# 21-gene testing were registered, as well as treatment received and physicians’ confidence levels in\n",
    "# their final recommendations. Results: A total of 219 consecutive patients were included from eight\n",
    "# Spanish centers: 30 in cohort A, 158 in cohort B, and 31 in cohort C. Ten patients were excluded from\n",
    "# the final analysis as CT was not initially recommended. After 21-gene testing, treatment decisions\n",
    "# changed from CT + endocrine therapy (ET) to ET alone for 67% of the whole group. In total, 30%\n",
    "# (95% confidence interval [CI] 15% to 49%), 73% (95% CI 65% to 80%), and 76% (95% CI 56% to 90%)\n",
    "# of patients ultimately received ET alone in cohorts A, B, and C, respectively. Physicians’ confidence\n",
    "# in their final recommendations increased in 34% of cases. Conclusions: Use of the 21-gene test\n",
    "# resulted in an overall 67% reduction in CT recommendation in patients considered candidates for CT.\n",
    "# Our findings indicate the substantial potential of the 21-gene test to guide CT recommendations in\n",
    "# patients with EBC considered to be at high risk of recurrence based on clinicopathological parameters,\n",
    "# regardless of nodal status or treatment setting.\"\"\"\n",
    "# ]\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "documents = [Document(text=abstract) for abstract in sample_abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# llm = OpenAI(model='gpt-3.5-turbo')\n",
    "# use gpt4-o\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document\n",
    "\n",
    "news = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\"\n",
    ")\n",
    "documents = [\n",
    "    Document(text=f\"{row['title']}: {row['text']}\") for i, row in news.iterrows()\n",
    "]\n",
    "# news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save first 10 of news to csv\n",
    "# news.iloc[:10].to_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # delete all nodes\n",
    "graph_store.structured_query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkoch/Library/Caches/pypoetry/virtualenvs/llama-index-cumQImzL-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 10/10 [00:00<00:00, 2339.66it/s]\n",
      "Extracting paths from text with schema:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  10%|█         | 1/10 [00:04<00:44,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='LOCATED_IN'), object=Entity(type='LOCATION', name='American Fork')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='One Year Anniversary')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='LOCATED_IN'), object=Entity(type='LOCATION', name='Western half of the U.S.')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='HAS'), object=Entity(type='EVENT', name='networking event')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='financial wellness center model')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='Drew Yergensen')), Triplet(subject=Entity(type='PERSON', name='Drew Yergensen'), relation=Relation(type='IS_A'), object=Entity(type='PERSON', name='KeyBank Utah market president')), Triplet(subject=Entity(type='PERSON', name='Drew Yergensen'), relation=Relation(type='IS_A'), object=Entity(type='PERSON', name='commercial banking leader')), Triplet(subject=Entity(type='ORGANIZATION', name='KeyBank'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='Jason Scorup')), Triplet(subject=Entity(type='PERSON', name='Jason Scorup'), relation=Relation(type='IS_A'), object=Entity(type='PERSON', name='KeyBank American Fork branch manager'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  20%|██        | 2/10 [00:07<00:26,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='XPeng'), relation=Relation(type='IS_A'), object=Entity(type='ORGANIZATION', name='Chinese electric-vehicle maker')), Triplet(subject=Entity(type='ORGANIZATION', name='XPeng'), relation=Relation(type='HAS'), object=Entity(type='TECHNOLOGY', name='assisted-driving technology')), Triplet(subject=Entity(type='ORGANIZATION', name='XPeng'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='stock'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  30%|███       | 3/10 [00:07<00:14,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='European Commission'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='ban equipment from Huawei and ZTE')), Triplet(subject=Entity(type='ORGANIZATION', name='Huawei Technologies Co.'), relation=Relation(type='LOCATED_IN'), object=Entity(type='LOCATION', name='China')), Triplet(subject=Entity(type='ORGANIZATION', name='ZTE Corp.'), relation=Relation(type='LOCATED_IN'), object=Entity(type='LOCATION', name='China')), Triplet(subject=Entity(type='ORGANIZATION', name='European Union'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='5G mobile networks')), Triplet(subject=Entity(type='ORGANIZATION', name='European Union'), relation=Relation(type='HAS'), object=Entity(type='LOCATION', name='China')), Triplet(subject=Entity(type='ORGANIZATION', name='European Union'), relation=Relation(type='HAS'), object=Entity(type='LOCATION', name='US')), Triplet(subject=Entity(type='ORGANIZATION', name='TikTok Inc.'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='data-collection practices')), Triplet(subject=Entity(type='ORGANIZATION', name='European Commission'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='5G toolbox')), Triplet(subject=Entity(type='ORGANIZATION', name='European Commission'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='block staff from using TikTok')), Triplet(subject=Entity(type='ORGANIZATION', name='Huawei'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='Thomas Seal'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  40%|████      | 4/10 [00:08<00:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='EVENT', name='Dáil almost suspended'), relation=Relation(type='HAS'), object=Entity(type='EVENT', name='Sinn Féin TD put pager in front of Minister during firefighters debate')), Triplet(subject=Entity(type='PERSON', name='John Brady'), relation=Relation(type='PART_OF'), object=Entity(type='ORGANIZATION', name='Sinn Féin')), Triplet(subject=Entity(type='PERSON', name='Darragh O’Brien'), relation=Relation(type='PART_OF'), object=Entity(type='ORGANIZATION', name='Government')), Triplet(subject=Entity(type='PERSON', name='Pearse Doherty'), relation=Relation(type='PART_OF'), object=Entity(type='ORGANIZATION', name='Sinn Féin')), Triplet(subject=Entity(type='PERSON', name='Darragh O’Brien'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='Minister for Housing')), Triplet(subject=Entity(type='EVENT', name='industrial action'), relation=Relation(type='PART_OF'), object=Entity(type='EVENT', name='dispute over pay and working conditions')), Triplet(subject=Entity(type='PERSON', name='Pearse Doherty'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='Sinn Féin deputy leader')), Triplet(subject=Entity(type='PERSON', name='Darragh O’Brien'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='firefighters')), Triplet(subject=Entity(type='ORGANIZATION', name='Sinn Féin'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='John Brady'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  50%|█████     | 5/10 [00:10<00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='Arsenal'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='Rice')), Triplet(subject=Entity(type='ORGANIZATION', name='Premier League'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='new'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  60%|██████    | 6/10 [00:14<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='FirstEnergy'), relation=Relation(type='HAS_ALIAS'), object=Entity(type='MISCELLANEOUS', name='NYSE:FE')), Triplet(subject=Entity(type='TIME', name='Tuesday'), relation=Relation(type='HAS'), object=Entity(type='EVENT', name='earnings results')), Triplet(subject=Entity(type='TIME', name='the same period'), relation=Relation(type='PART_OF'), object=Entity(type='TIME', name='quarter'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n",
      "base model cls : <class 'pydantic.v1.main.KGSchema'>\n",
      "schema of base model cls:\n",
      "{'title': 'KGSchema', 'description': 'Knowledge Graph Schema.', 'type': 'object', 'properties': {'triplets': {'title': 'Triplets', 'type': 'array', 'items': {'$ref': '#/definitions/Triplet'}}}, 'required': ['triplets'], 'definitions': {'Entity': {'title': 'Entity', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS']\", 'enum': ['PRODUCT', 'MARKET', 'TECHNOLOGY', 'EVENT', 'CONCEPT', 'ORGANIZATION', 'PERSON', 'LOCATION', 'TIME', 'MISCELLANEOUS'], 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['type', 'name']}, 'Relation': {'title': 'Relation', 'type': 'object', 'properties': {'type': {'title': 'Type', 'description': \"Relation in a knowledge graph. Only extract relations with types that are listed as valid: typing.Literal['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS']\", 'enum': ['USED_BY', 'USED_FOR', 'LOCATED_IN', 'PART_OF', 'WORKED_ON', 'HAS', 'IS_A', 'BORN_IN', 'DIED_IN', 'HAS_ALIAS'], 'type': 'string'}}, 'required': ['type']}, 'Triplet': {'title': 'Triplet', 'type': 'object', 'properties': {'subject': {'$ref': '#/definitions/Entity'}, 'relation': {'$ref': '#/definitions/Relation'}, 'object': {'$ref': '#/definitions/Entity'}}, 'required': ['subject', 'relation', 'object']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  70%|███████   | 7/10 [00:14<00:05,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='USED_BY'), object=Entity(type='PERSON', name='Jia Jingdong')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='PART_OF'), object=Entity(type='PRODUCT', name='Vivo X90 series')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='triple rear camera unit')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='USED_FOR'), object=Entity(type='CONCEPT', name='photography')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='MediaTek Dimensity 9200+ SoC')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='TECHNOLOGY', name='Wi-Fi 7 connectivity')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='6.78-inch 1.5K curved AMOLED display')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='16GB of RAM')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='1TB of inbuilt storage')), Triplet(subject=Entity(type='PRODUCT', name='Vivo X90s'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='4,690mAh battery'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  80%|████████  | 8/10 [00:14<00:02,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='Chevron'), relation=Relation(type='IS_A'), object=Entity(type='ORGANIZATION', name='company')), Triplet(subject=Entity(type='ORGANIZATION', name='Chevron'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='stock')), Triplet(subject=Entity(type='PRODUCT', name='stock'), relation=Relation(type='USED_BY'), object=Entity(type='ORGANIZATION', name='Chevron')), Triplet(subject=Entity(type='PRODUCT', name='stock'), relation=Relation(type='LOCATED_IN'), object=Entity(type='MARKET', name='NYSE')), Triplet(subject=Entity(type='PRODUCT', name='stock'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='decline')), Triplet(subject=Entity(type='CONCEPT', name='decline'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='past 90-days')), Triplet(subject=Entity(type='CONCEPT', name='fact'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='Q2 consensus earnings estimates')), Triplet(subject=Entity(type='CONCEPT', name='Q2 consensus earnings estimates'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='same time frame'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:  90%|█████████ | 9/10 [00:16<00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='Epic'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='MetaHuman Animator')), Triplet(subject=Entity(type='PRODUCT', name='MetaHuman Animator'), relation=Relation(type='USED_FOR'), object=Entity(type='CONCEPT', name='capturing an actor’s facial performance')), Triplet(subject=Entity(type='PRODUCT', name='MetaHuman Animator'), relation=Relation(type='USED_FOR'), object=Entity(type='PRODUCT', name='MetaHuman')), Triplet(subject=Entity(type='ORGANIZATION', name='Epic'), relation=Relation(type='HAS'), object=Entity(type='PRODUCT', name='Live Link Face iOS app'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema: 100%|██████████| 10/10 [00:20<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities predicted: triplets=[Triplet(subject=Entity(type='ORGANIZATION', name='Ryanair'), relation=Relation(type='HAS'), object=Entity(type='PERSON', name='Aidan Murray')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='IS_A'), object=Entity(type='PERSON', name='chief pilot')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='BORN_IN'), object=Entity(type='TIME', name='1965')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='WORKED_ON'), object=Entity(type='ORGANIZATION', name='Ryanair')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='28 years')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='TIME', name='2020')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='sexual harassment claims')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='inappropriate and unacceptable behaviour')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='altering flight rosters')), Triplet(subject=Entity(type='PERSON', name='Aidan Murray'), relation=Relation(type='HAS'), object=Entity(type='CONCEPT', name='breach of anti-harassment policy'))]\n",
      "type of entities: <class 'pydantic.v1.main.KGSchema'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "from schema_llm import SchemaLLMPathExtractor\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    # possible_entities=entities,\n",
    "    # possible_relations=relations,\n",
    "    # kg_validation_schema=validation_schema,\n",
    "    # if false, allows for values outside of the schema\n",
    "    # useful for using the schema as a suggestion\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents[:10],\n",
    "    kg_extractors=[kg_extractor],\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wen's schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_properties = {\n",
    "    \"PROTEIN\": [\n",
    "        {\"property\": \"name\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"synonyms\", \"type\": \"LIST\"},\n",
    "        {\"property\": \"taxid\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"id\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"accession\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "    \"DRUG\": [\n",
    "        {\"property\": \"name\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"synonyms\", \"type\": \"LIST\"},\n",
    "        {\"property\": \"id\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "    \"DISEASE\": [\n",
    "        {\"property\": \"name\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"synonyms\", \"type\": \"LIST\"},\n",
    "        {\"property\": \"id\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "relation_properties = {\n",
    "    \"ASSOCIATED_WITH\": [\n",
    "        {\"property\": \"evidence_type\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"source\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"score\", \"type\": \"FLOAT\"},\n",
    "        {\"property\": \"publications\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"action\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"number_publications\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "    \"ACTS_ON\": [\n",
    "        {\"property\": \"directionality\", \"type\": \"BOOLEAN\"},\n",
    "        {\"property\": \"action\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"source\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"score\", \"type\": \"FLOAT\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# defines possible relationships between entities and the directionality\n",
    "relationships = [\n",
    "    {\"start\": \"DRUG\", \"end\": \"PROTEIN\", \"type\": \"ACTS_ON\"},\n",
    "    {\"start\": \"PROTEIN\", \"end\": \"PROTEIN\", \"type\": \"ACTS_ON\"},\n",
    "    {\"start\": \"PROTEIN\", \"end\": \"DISEASE\", \"type\": \"ASSOCIATED_WITH\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "from llama_index.core.bridge.pydantic import create_model, Field\n",
    "\n",
    "DEFAULT_ENTITY_PROPERTIES = {\n",
    "    \"PERSON\": [\n",
    "        {\"property\": \"profession\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"role\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "    \"PRODUCT\": [\n",
    "        {\"property\": \"price\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "    \"LOCATION\": [{\"property\": \"country\", \"type\": \"STRING\"}],\n",
    "    \"ORGANIZATION\": [\n",
    "        {\"property\": \"ticker\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"industry\", \"type\": \"STRING\"},\n",
    "        {\"property\": \"sector\", \"type\": \"STRING\"},\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = DEFAULT_ENTITY_PROPERTIES.get(entity_type, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"typing.Literal['PERSON', 'PRODUCT', 'LOCATION', 'ORGANIZATION']\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_entities = Literal[tuple(DEFAULT_ENTITY_PROPERTIES.keys())]\n",
    "str(possible_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.Entity"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates entity_fields dictionary\n",
    "entity_fields = {\n",
    "    \"type\": (\n",
    "        possible_entities,\n",
    "        Field(\n",
    "            ...,\n",
    "            description=(\n",
    "                \"Entity in a knowledge graph. Only extract entities with types that are listed as valid: \"\n",
    "                + str(possible_entities)\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    \"name\": (str, ...),\n",
    "}\n",
    "\n",
    "for entity_type, properties in DEFAULT_ENTITY_PROPERTIES.items():\n",
    "    for prop in properties:\n",
    "        prop_name = prop[\"property\"]\n",
    "        prop_type = prop[\"type\"]\n",
    "        entity_fields[prop_name] = (\n",
    "            Optional[str],\n",
    "            Field(\n",
    "                default=None,\n",
    "                description=f\"{prop_name.capitalize()} of the entity {entity_type.upper()}, if available.\",\n",
    "            ),\n",
    "        )\n",
    "entity_cls = create_model(\"Entity\", **entity_fields)\n",
    "entity_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': (typing.Literal['PERSON', 'PRODUCT', 'LOCATION', 'ORGANIZATION'],\n",
       "  FieldInfo(default=Ellipsis, description=\"Entity in a knowledge graph. Only extract entities with types that are listed as valid: typing.Literal['PERSON', 'PRODUCT', 'LOCATION', 'ORGANIZATION']\", extra={})),\n",
       " 'name': (str, Ellipsis),\n",
       " 'profession': (typing.Optional[str],\n",
       "  FieldInfo(description='Profession of the entity PERSON, if available.', extra={})),\n",
       " 'role': (typing.Optional[str],\n",
       "  FieldInfo(description='Role of the entity PERSON, if available.', extra={})),\n",
       " 'price': (typing.Optional[str],\n",
       "  FieldInfo(description='Price of the entity PRODUCT, if available.', extra={})),\n",
       " 'country': (typing.Optional[str],\n",
       "  FieldInfo(description='Country of the entity LOCATION, if available.', extra={})),\n",
       " 'ticker': (typing.Optional[str],\n",
       "  FieldInfo(description='Ticker of the entity ORGANIZATION, if available.', extra={})),\n",
       " 'industry': (typing.Optional[str],\n",
       "  FieldInfo(description='Industry of the entity ORGANIZATION, if available.', extra={})),\n",
       " 'sector': (typing.Optional[str],\n",
       "  FieldInfo(description='Sector of the entity ORGANIZATION, if available.', extra={}))}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'PERSON': [{'property': 'profession', 'type': 'STRING'}, {'property': 'role', 'type': 'STRING'}], 'PRODUCT': [{'property': 'price', 'type': 'NUMBER'}], 'LOCATION': [{'property': 'country', 'type': 'STRING'}], 'ORGANIZATION': [{'property': 'founded', 'type': 'DATE'}]}\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(DEFAULT_ENTITY_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any, Dict, List, Optional, Union, Literal\n",
    "from llama_index.core.bridge.pydantic import create_model, Field, BaseModel, validator\n",
    "\n",
    "entity_property_fields = {}\n",
    "for entity_type, properties in DEFAULT_ENTITY_PROPERTIES.items():\n",
    "    property_fields = {\n",
    "        prop[\"property\"]: (\n",
    "            str\n",
    "            if prop[\"type\"] == \"STRING\"\n",
    "            else float\n",
    "            if prop[\"type\"] == \"NUMBER\"\n",
    "            else str,\n",
    "            ...,\n",
    "        )\n",
    "        for prop in properties\n",
    "    }\n",
    "    entity_property_fields[entity_type] = create_model(\n",
    "        entity_type,\n",
    "        type=(Literal[entity_type], Field(...)),\n",
    "        name=(str, ...),\n",
    "        **property_fields\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': pydantic.v1.main.PERSON,\n",
       " 'PRODUCT': pydantic.v1.main.PRODUCT,\n",
       " 'LOCATION': pydantic.v1.main.LOCATION,\n",
       " 'ORGANIZATION': pydantic.v1.main.ORGANIZATION}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_property_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PERSON',\n",
       " 'type': 'object',\n",
       " 'properties': {'type': {'title': 'Type',\n",
       "   'enum': ['PERSON'],\n",
       "   'type': 'string'},\n",
       "  'name': {'title': 'Name', 'type': 'string'},\n",
       "  'profession': {'title': 'Profession', 'type': 'string'},\n",
       "  'role': {'title': 'Role', 'type': 'string'}},\n",
       " 'required': ['type', 'name', 'profession', 'role']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_property_fields.get(\"PERSON\").schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.ModelMetaclass"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(PropertiesModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_schemas = {}\n",
    "for entity_type, properties in DEFAULT_ENTITY_PROPERTIES.items():\n",
    "    property_schema = {}\n",
    "    for prop in properties:\n",
    "        if prop[\"type\"] == \"STRING\":\n",
    "            property_schema[prop[\"property\"]] = (Optional[str], None)\n",
    "        elif prop[\"type\"] == \"NUMBER\":\n",
    "            property_schema[prop[\"property\"]] = (Optional[float], None)\n",
    "        elif prop[\"type\"] == \"DATE\":\n",
    "            property_schema[prop[\"property\"]] = (Optional[str], None)\n",
    "    property_schemas[entity_type] = create_model(\n",
    "        f\"{entity_type}_Properties\", **property_schema\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': pydantic.v1.main.PERSON_Properties,\n",
       " 'PRODUCT': pydantic.v1.main.PRODUCT_Properties,\n",
       " 'LOCATION': pydantic.v1.main.LOCATION_Properties,\n",
       " 'ORGANIZATION': pydantic.v1.main.ORGANIZATION_Properties}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.ModelMetaclass"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(property_schemas.get(\"PERSON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PERSON_Properties',\n",
       " 'type': 'object',\n",
       " 'properties': {'profession': {'title': 'Profession', 'type': 'string'},\n",
       "  'role': {'title': 'Role', 'type': 'string'}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_schemas.get(\"PERSON\").schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'test_person',\n",
       " 'type': 'object',\n",
       " 'properties': {'profession': {'title': 'Profession', 'type': 'string'},\n",
       "  'role': {'title': 'Role', 'type': 'string'},\n",
       "  'name': {'title': 'Name', 'type': 'string'}},\n",
       " 'required': ['name']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = create_model(\n",
    "    \"test_person\",\n",
    "    profession=(Optional[str], None),\n",
    "    role=(Optional[str], None),\n",
    "    name=(str, ...),\n",
    ")\n",
    "p.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.v1.main.ModelMetaclass"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
